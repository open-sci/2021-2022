{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75da9b0e",
   "metadata": {},
   "source": [
    "# Open Science project 2021-22 personal diary\n",
    "## Team Don't lock up\n",
    "\n",
    "## Research questions:\n",
    "- Which is the coverage, in terms of citations, of the open access journals in DOAJ according to the data available in OpenCitations? \n",
    "- How many citations DOAJ journals receive? \n",
    "- How many citations DOAJ journals do? \n",
    "- How many of these citations involves articles published in open access journals as both citing and cited entities? \n",
    "- What is the trend (increasing? decreasing?) in time of the availability of such citations involving journals in DOAJ?\n",
    "\n",
    "## 28-03-22 and 29-03-22 First research on the topics\n",
    "After agreeing on team members, team name and research questions, the first task at hand is to prepare the abstract for our research, following [Emerald Publishing recommendations](https://www.emeraldgrouppublishing.com/how-to/authoring-editing-reviewing/write-article-abstract).\n",
    "The abstract will have to feature the Purpose of our research, the Study design/methodology/approach, our Findings and the Originality/Value of our research. \n",
    "\n",
    "I did some research on [OpenCitations' COCI](https://opencitations.net/index/coci), [Crossref](https://www.crossref.org/documentation/) and [DOAJ](https://doaj.org/) and try to reformulate the research questions in order to find relevant points to bring to the first team meeting, which we agreed would be before the next lecture, 30/03/22 morning.\n",
    "\n",
    "We will need to address the research questions about DOAJ journals citing and cited articles according to OpenCitations, citations with citing and cited DOIs published in open access journals and finally the presence of trends over time of the availability of such citations in DOAJ journals. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6208869",
   "metadata": {},
   "source": [
    "## 30-03-22 First version of the abstract\n",
    "\n",
    "We had a team meeting to write the abstract together. We reflected on the research questions and came up with a first version, to be updated as we continue the project. \n",
    "\n",
    "---\n",
    "### Purpose\n",
    "Citations are always important in scientific research. In the domain of Open Science, the Initiative for Open Citations promotes the availability of data on citations with OpenCitations. *As of March 2021, the fraction of publications with open references has grown from 1% to 87% out of 54.2 million articles with references deposited with Crossref.* ([i4oc.org](https://i4oa.org/))\n",
    "\n",
    "Our goal is to find out \n",
    "* about the coverage of articles from open access journals in DOAJ journals as citing and cited articles,\n",
    "* how many citations do DOAJ journals receive and do, and how many of these citations involve open access articles as both citing and cited entities,\n",
    "* as well as the presence of trends over time of the availability of citations involving articles published in open access journals in DOAJ journals.\n",
    "\n",
    "### Approach\n",
    "We used the data available in OpenCitations, such as the Index of Crossref open DOI-to-DOI citations (COCI). We used the REST API to use the data available in DOAJ and OpenCitations.\n",
    "\n",
    "### Findings\n",
    "We revealed that the coverage of open citations in DOAJ can be improved, and that many of these citations involve articles which are not in open access, but that the trend is still increasing.\n",
    "\n",
    "### Originality\n",
    "Our research is valuable for the open access domain, by revealing trends on the data of DOAJ. In the future more questions can be build on our research.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0912221b",
   "metadata": {},
   "source": [
    "## 06-04-2022 First version of the DMP\n",
    "We held a team meeting on Teams to fill the Data Management Plan together, using the templates offered by Argos. After the general information about the DMP, we filled out information about two datasets, one for the software that we will develop and one for the data that we will produce. \n",
    "\n",
    "It was relatively difficult to answer all of the questions since we have not actually started the research, but it allowed us to think about whihc specific aspects to take into account once we start the project in order to make it compliant to Open Science standards and requirements. \n",
    "We first started filling the Horizon Europe template, but due to some bug that didn't allow us to submit it, we had to use Horizon 2020 and refill it entirely.\n",
    "\n",
    "The vesion 0 of the DMP can be found at [this address](https://doi.org/10.5281/zenodo.6417368)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6613217",
   "metadata": {},
   "source": [
    "## 10-04-2022 Protocol\n",
    "We had a meeting on Teams to talk about the protocol, since we had to produce the first verison of it before the class on Wednesday. We first tried to sketch the protocol with images to figure out how to precisely answer the research questions one by one. \n",
    "\n",
    "When trying to understand exactly how to handle the research, we looked into the possibilities offered by OpenCitations Indexes: mainly the SPARQL endpoint and the API. \n",
    "\n",
    "We tried to produce drafts of SPARQL queries that would answer our questions.\n",
    "### Which is the coverage, in terms of citations, of the open access journals in DOAJ according to the data available in OpenCitations?\n",
    "- *How many citations DOAJ journals receive?*\n",
    "\n",
    "We will query on all citations inside COCI and CROCI, filtering only those with DOAJ journals as cited.\n",
    "- *How many citations DOAJ journals do?*\n",
    "\n",
    "We will query on all citations inside COCI and CROCI, filtering only those with DOAJ journals as citing.\n",
    "- *How many of these citations involves articles published in open access journals as both citing and cited entities?*\n",
    "\n",
    "Combining the two previous dataframes, we extract only those with open access journals as citing and cited entities. We discovered that with the API for COCI, there is a way to check in the metadata for an article if there is an open access entry for it. \n",
    "- *What is the trend (increasing? decreasing?) in time of the availability of such citations involving journals in DOAJ?*\n",
    "\n",
    "We will sort the previous list by year and study the presence or absence of a trend. Eventually we will extract a plot or other visualizing tool to present the results.\n",
    "\n",
    "We then used [protocols.io](protocols.io) to write the first version of the protocol (a very basic draft), available at [this link](dx.doi.org/10.17504/protocols.io.n92ldz598v5b/v1) in the Open Science 2021-22 repository created by prof. Silvio Peroni. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9c12a5",
   "metadata": {},
   "source": [
    "## 15-04-22 and 16-04-22 Research in order to revise the protocol\n",
    "Prof. Peroni asked us to refine our protocol before evaluation by the other team and asked us to be more precise. \n",
    "\n",
    "I did a little research on [Google Scholar](https://scholar.google.com/) trying to find papers that would be useful for our research, here are two of them that I found relevant: \n",
    "- David J. Solomon, Mikael Laakso, Bo-Christer Björk, \"A longitudinal comparison of citation rates and growth among open access journals\",Journal of Informetrics,Vol. 7, Issue 3, 2013, pp. 642-650. [https://doi.org/10.1016/j.joi.2013.03.008](https://doi.org/10.1016/j.joi.2013.03.008)\n",
    "- Chifumi Nishioka, Michael Färber, \"Evaluating the Availability of Open Citation Data\", BIRNDL@ SIGIR. 2019. p. 123-129. [link](http://ceur-ws.org/Vol-2414/paper13.pdf)\n",
    "\n",
    "I also looked more into COCI's API and DOAJ's API and dump, trying to understand how we will be able to retrieve data useful for our research. I downloaded the [DOAJ public data dump](https://doaj.org/docs/public-data-dump/) to understand which metadata about the journals is available. I discovered that the ISSN and EISSN of the journals may be the best way to filter then the citations in OpenCitations, because for each article DOI, the metadata holding the information of the source of the article (i.e. the ISSN of the journal where it was published) can be retrieved through the API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f026a5",
   "metadata": {},
   "source": [
    "## 19-04-22 and 20-04-22 Revision of the protocol (v.2)\n",
    "We had a team meeting on Teams to talk about the protocol and make the steps more precise. \n",
    "I shared the information that I found about the DOAJ dump and COCI API and we discussed how we would retrieve data for our research, we are still indecisive about using the SPARQL endpoint or the API of OpenCitations and plan on asking some information to prof. Peroni about it. \n",
    "We defined better each step of the protocol, explaining which formats of data we will use at each step and probably the method used to do so, even though we are not entirely fixed upon that since we haven't started developing the software yet. \n",
    "\n",
    "We will mostly use JSON and CSV, and probably also use [pandas library](https://pandas.pydata.org/) of python to use the dataframe structure and query on it. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36f2496",
   "metadata": {},
   "source": [
    "## 21-04-22 Publication of the protocol and review of the other team's protocol\n",
    "We published the second version of the protocol, available at [this link](https://dx.doi.org/10.17504/protocols.io.n92ldz598v5b/v2), after adding some python code explaining how we will connect to the API, thanks to the tests done by Alessandro.\n",
    "\n",
    "I also published on Qeios [my review](https://doi.org/10.32388/MOBTWR) of the team La Chouffe's protocol."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c551b81",
   "metadata": {},
   "source": [
    "## 26-04-22 Revision of the DMP and rebuttal letter\n",
    "We had a team meeting to address the issues expressed by the two reviews of our colleagues about the first version of our DMP. We then wrote together the [second version of the DMP](https://doi.org/10.5281/zenodo.6491184), taking into account their remarks and writing also a [response letter](https://doi.org/10.5281/zenodo.6492439) to these reviews. It allowed us to think again on some parts of the DMP that we didn't understand on the first version, when we did not yet have a clear idea on how to realize the project. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd59f93",
   "metadata": {},
   "source": [
    "## 03-05-22 Team meeting for writing the software\n",
    "We met with the team to try to extract the data we need for the project in python. We tried a lot of different techniques, and after realizing that with the API it would take too much time to make requests on all of OpenCitations dataset, we downloaded the public data dump in zip files and searched for methods to work with zipped files. There is the library [zipfile.py](https://docs.python.org/3/library/zipfile.html), and we started writing code to extract the first csv from the OpenCitations dump through this library.\n",
    "We also discovered the [vaex library](https://vaex.io/docs/index.html) to process huge quantity of data in a faster way than pandas.\n",
    "\n",
    "Upon doing research on other projects that had to deal with the same quantity of data, I found the [Coronavirus Open Citations Dataset](https://opencitations.github.io/coronavirus/) by Prof. Peroni, and taking a look at [the method](https://github.com/opencitations/coronavirus/blob/master/data.ipynb) he used to extract data, I tried to test out the doaj api to extract the articles from just one journal: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7474b798",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n",
      "10.2533/chimia.2013.149\n",
      "this article doesn't have a doi assigned in doaj api\n",
      "10.2533/chimia.2011.814\n",
      "this article doesn't have a doi assigned in doaj api\n",
      "this article doesn't have a doi assigned in doaj api\n",
      "10.2533/chimia.2014.812\n",
      "this article doesn't have a doi assigned in doaj api\n",
      "10.2533/chimia.2017.387\n",
      "this article doesn't have a doi assigned in doaj api\n",
      "10.2533/chimia.2017.773\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "from requests import get\n",
    "from json import loads, load, dump\n",
    "import logging\n",
    "\n",
    "print(\"hey\")\n",
    "logging_level = logging.INFO\n",
    "\n",
    "logging.basicConfig(format='%(levelname)s: %(message)s.')\n",
    "log = logging.getLogger()\n",
    "log.setLevel(logging_level)\n",
    "\n",
    "dois = set()\n",
    "doaj_query = \"https://doaj.org/api/search/articles/issn:0009-4293\"\n",
    "doaj_data = get(doaj_query)\n",
    "if doaj_data.status_code == 200:\n",
    "    doaj_data.encoding=\"utf-8\"\n",
    "    \n",
    "    doaj_json = loads(doaj_data.text).get(\"results\")\n",
    "    \n",
    "    for item in doaj_json:\n",
    "        if item[\"bibjson\"][\"identifier\"][0][\"type\"] == \"doi\":\n",
    "            print(item[\"bibjson\"][\"identifier\"][0][\"id\"])\n",
    "            dois.add(item[\"bibjson\"][\"identifier\"][0][\"id\"])\n",
    "        else:\n",
    "            print(\"this article doesn't have a doi assigned in doaj api\")\n",
    "print(len(dois))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34a5d1d",
   "metadata": {},
   "source": [
    "This is actually only the first 10 of the response but it was just a test to use the api. Nonetheless we \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865a1b97",
   "metadata": {},
   "source": [
    "Test to import journal information from DOAJ articles dump and crate a json file with information we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce57f9e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_66920/1516080227.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m                 \u001b[0mjournal_eissn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"type\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"doi\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                 \u001b[0mart_doi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mjournal_title\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marticle\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"bibjson\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"journal\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"title\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import json\n",
    "\n",
    "doi_list = {}\n",
    "doi_list_problem = []\n",
    "tar = tarfile.open(\"doaj_article_data_2022-05-01.tar.gz\", \"r:gz\")\n",
    "for tarinfo in tar:\n",
    "   \n",
    "    ciao = tar.extractfile(tarinfo)\n",
    "    p = json.load(ciao)\n",
    "    \n",
    "    for article in p:\n",
    "        for el in article[\"bibjson\"][\"identifier\"]:\n",
    "            if el[\"type\"] == \"pissn\":\n",
    "                journal_issn = el[\"id\"]\n",
    "            if el[\"type\"] == \"eissn\":\n",
    "                journal_eissn = el[\"id\"]\n",
    "            if el[\"type\"] == \"doi\":\n",
    "                art_doi = el[\"id\"]\n",
    "        journal_title=article[\"bibjson\"][\"journal\"][\"title\"]\n",
    "        \n",
    "        key_dict = f\"{journal_issn}{journal_eissn}\"\n",
    "        \n",
    "        if key_dict in doi_list:\n",
    "            doi_list[key_dict][\"dois\"].append(art_doi)\n",
    "        else:\n",
    "            doi_list[key_dict]={\"title\":journal_title, \"pissn\":journal_issn, \"eissn\":journal_eissn, \"dois\":[art_doi]}\n",
    "        \n",
    "\n",
    "        \n",
    "# Save a json file with all DOIs\n",
    "with open('doi.json', 'w', encoding='utf8') as json_file:\n",
    "    json.dump(doi_list, json_file, ensure_ascii=False)\n",
    "    \n",
    "    \n",
    "#TODO: controllare unicità identifier -> uguale numero giornale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe2224e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'last_updated': '2021-02-02T08:38:31Z', 'bibjson': {'identifier': [{'id': '1779-627X', 'type': 'pissn'}, {'id': '1779-6288', 'type': 'eissn'}, {'id': '10.1051/ijsmdo:2008025', 'type': 'doi'}], 'journal': {'volume': '2', 'number': '3', 'country': 'FR', 'issns': ['1779-627X', '1779-6288'], 'publisher': 'EDP Sciences', 'language': ['EN'], 'title': 'International Journal for Simulation and Multidisciplinary Design Optimization'}, 'month': '7', 'end_page': '192', 'keywords': ['collaborative optimization method', 'fe analysis', 'aerospace application'], 'year': '2008', 'start_page': '187', 'subject': [{'code': 'T55.4-60.8', 'scheme': 'LCC', 'term': 'Industrial engineering. Management engineering'}, {'code': 'T11.95-12.5', 'scheme': 'LCC', 'term': 'Industrial directories'}], 'author': [{'name': 'Guadagni L.'}], 'link': [{'content_type': 'pdf', 'type': 'fulltext', 'url': 'https://www.ijsmdo.org/articles/smdo/pdf/2008/03/asmdo4108.pdf'}], 'abstract': 'The work introduces a computational method for the optimization of aerospace preliminary \\ndesigns. It was developed considering a collaborative approach to solve the sizing optimization of a structure \\nmodel defined by finite element method and by a large number of subsystems. A brief \\nintroduction explains how the collaborative optimization method can be used for general \\nstructural problem and how this approach can offer many advantages to the computation analyses. Central \\ndiscussion is the description of an automatic procedure defined by three \\ndeterministic optimization codes and their interface systems with the MSC.Nastran environment. They \\ndecompose the structure complexity executing an interface algorithm for FE models searching an optimized \\nsolution for the structural subsystems respecting different kinds of constraints. Furthermore, in order \\nto show the uses of the procedure in an industrial context, two realistic applications for the minimum design are \\nalso discussed. The results show a good comparison with the commercial solvers, taking out better results in \\nless time processing and finding new alternative design configurations.', 'title': 'Development of a collaborative optimization tool for the \\nsizing design of aerospace structures'}, 'admin': {'seal': True}, 'created_date': '2019-10-29T10:25:02Z', 'id': 'a2f355867803488ba040a02b8dc2844d'}\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "import tarfile\n",
    "import json\n",
    "\n",
    "doi_list = {}\n",
    "doi_list_problem = []\n",
    "tar = tarfile.open(\"doaj_article_data_2022-05-01.tar.gz\", \"r:gz\")\n",
    "for tarinfo in tar:\n",
    "   \n",
    "    ciao = tar.extractfile(tarinfo)\n",
    "    p = json.load(ciao)\n",
    "    print(p[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d4f6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "import tarfile\n",
    "import json\n",
    "\n",
    "doi_list = {}\n",
    "doi_list_problem = []\n",
    "tar = tarfile.open(\"doaj_article_data_2022-05-01.tar.gz\", \"r:gz\")\n",
    "for tarinfo in tar:\n",
    "   \n",
    "    ciao = tar.extractfile(tarinfo)\n",
    "    p = json.load(ciao)\n",
    "    \n",
    "    for article in p:\n",
    "        if\n",
    "        for el in article[\"bibjson\"][\"identifier\"]:\n",
    "            \n",
    "            try\n",
    "            \n",
    "            except KeyError:\n",
    "                \n",
    "                append record to Wrong_doi\n",
    "                \n",
    "            \n",
    "\n",
    "            \n",
    "        journal_title=article[\"bibjson\"][\"journal\"][\"title\"]\n",
    "        \n",
    "        key_dict = f\"{journal_issn}{journal_eissn}\"\n",
    "        \n",
    "        if key_dict in doi_list:\n",
    "            doi_list[key_dict][\"dois\"].append(art_doi)\n",
    "        else:\n",
    "            doi_list[key_dict]={\"title\":journal_title, \"pissn\":journal_issn, \"eissn\":journal_eissn, \"dois\":[art_doi]}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59d52a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
